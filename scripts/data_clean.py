#!/usr/bin/env python3
"""
KPPé¢˜ç›®æ•°æ®æ¸…æ´—è„šæœ¬
åŠŸèƒ½ï¼šæ¸…æ´—å’Œæ ¼å¼åŒ–å·²é‡‡é›†çš„é¢˜ç›®æ•°æ®ï¼Œæå–ç¿»è¯‘æ•°æ®
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import os

# é…ç½®
DATA_DIR = Path(__file__).parent.parent / "data"
QUESTIONS_DIR = DATA_DIR / "questions"
TRANSLATIONS_DIR = DATA_DIR / "translations"
IMAGES_DIR = Path(__file__).parent.parent / "images"

def clean_text(text: str) -> str:
    """æ¸…æ´—æ–‡æœ¬ï¼šå»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ"""
    if not text:
        return ""
    # å»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    # å°†å¤šä¸ªè¿ç»­ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    # å»é™¤å¤šä½™çš„æ¢è¡Œ
    text = re.sub(r'\n+', ' ', text)
    return text

def separate_bilingual_text(text: str) -> Tuple[str, Optional[str]]:
    """åˆ†ç¦»åŒè¯­æ–‡æœ¬ï¼ˆé©¬æ¥æ–‡+è‹±æ–‡ï¼‰
    
    Returns:
        (english_text, translation_text): è‹±æ–‡åŸæ–‡å’Œç¿»è¯‘æ–‡æœ¬
    """
    if not text:
        return "", None
    
    # å°è¯•è¯†åˆ«åŒè¯­æ–‡æœ¬çš„æ¨¡å¼
    # æ¨¡å¼1: é©¬æ¥æ–‡å¥å­ + è‹±æ–‡å¥å­ï¼ˆé€šå¸¸è‹±æ–‡åœ¨é©¬æ¥æ–‡åé¢ï¼‰
    # æ¨¡å¼2: é©¬æ¥æ–‡ + ç©ºæ ¼ + è‹±æ–‡ï¼ˆå¦‚ "2 tahun 2 years"ï¼‰
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜æ˜¾çš„è‹±æ–‡å•è¯ï¼ˆå¤§å†™å­—æ¯å¼€å¤´çš„å•è¯é€šå¸¸æ˜¯è‹±æ–‡å¥å­ï¼‰
    # æˆ–è€…åŒ…å«æ•°å­—+è‹±æ–‡çš„ç»„åˆï¼ˆå¦‚ "2 years"ï¼‰
    
    # ç®€å•ç­–ç•¥ï¼šå¦‚æœæ–‡æœ¬åŒ…å«å¸¸è§è‹±æ–‡å•è¯æ¨¡å¼ï¼Œå°è¯•åˆ†ç¦»
    # æ›´å¤æ‚çš„ç­–ç•¥éœ€è¦è¯­è¨€æ£€æµ‹åº“
    
    # å½“å‰ç­–ç•¥ï¼šä¿æŒåŸæ ·ï¼Œè‹±æ–‡éƒ¨åˆ†ä½œä¸ºä¸»è¦æ–‡æœ¬
    # ç¿»è¯‘éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ä¸­æ–‡ï¼‰ä¼šåœ¨åç»­å¤„ç†ä¸­æå–
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–‡
    has_chinese = bool(re.search(r'[\u4e00-\u9fff]', text))
    
    if has_chinese:
        # å¦‚æœæœ‰ä¸­æ–‡ï¼Œå°è¯•åˆ†ç¦»
        # é€šå¸¸æ ¼å¼ï¼šè‹±æ–‡ + ä¸­æ–‡ æˆ– ä¸­æ–‡ + è‹±æ–‡
        # è¿™é‡Œç®€å•å¤„ç†ï¼šä¿ç•™è‹±æ–‡éƒ¨åˆ†ï¼Œæå–ä¸­æ–‡éƒ¨åˆ†
        chinese_parts = re.findall(r'[\u4e00-\u9fff]+', text)
        if chinese_parts:
            # ç§»é™¤ä¸­æ–‡éƒ¨åˆ†ï¼Œä¿ç•™è‹±æ–‡
            english_text = re.sub(r'[\u4e00-\u9fff]+', '', text)
            english_text = clean_text(english_text)
            translation_text = ' '.join(chinese_parts)
            return english_text, translation_text
    
    # å¦‚æœæ²¡æœ‰ä¸­æ–‡ï¼Œä¿æŒåŸæ ·ï¼ˆé©¬æ¥æ–‡+è‹±æ–‡æ··åˆï¼‰
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦å°†é©¬æ¥æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡
    # è¿™é‡Œæš‚æ—¶ä¿æŒåŸæ ·ï¼Œè‹±æ–‡éƒ¨åˆ†ä½œä¸ºä¸»è¦æ˜¾ç¤ºæ–‡æœ¬
    cleaned = clean_text(text)
    return cleaned, None

def extract_translation_from_text(text: str) -> Optional[str]:
    """ä»æ–‡æœ¬ä¸­æå–ç¿»è¯‘éƒ¨åˆ†ï¼ˆä¸­æ–‡ï¼‰"""
    if not text:
        return None
    
    # æå–ä¸­æ–‡å­—ç¬¦
    chinese_chars = re.findall(r'[\u4e00-\u9fff]+', text)
    if chinese_chars:
        return ' '.join(chinese_chars)
    
    return None

def validate_question_data(question_data: Dict) -> Tuple[bool, List[str]]:
    """éªŒè¯é¢˜ç›®æ•°æ®çš„å®Œæ•´æ€§"""
    errors = []
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = ["id", "part", "question_number", "question_text", "options", "correct_answer"]
    for field in required_fields:
        if field not in question_data:
            errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
    
    # æ£€æŸ¥é¢˜ç›®æ–‡æœ¬
    if "question_text" in question_data:
        if not question_data["question_text"] or not question_data["question_text"].strip():
            errors.append("é¢˜ç›®æ–‡æœ¬ä¸ºç©º")
    
    # æ£€æŸ¥é€‰é¡¹
    if "options" in question_data:
        options = question_data["options"]
        if not isinstance(options, list) or len(options) < 2:
            errors.append("é€‰é¡¹æ•°é‡ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦2ä¸ªé€‰é¡¹ï¼‰")
        else:
            # æ£€æŸ¥æ¯ä¸ªé€‰é¡¹
            for idx, option in enumerate(options):
                if not isinstance(option, dict):
                    errors.append(f"é€‰é¡¹ {idx} æ ¼å¼é”™è¯¯")
                    continue
                if "label" not in option:
                    errors.append(f"é€‰é¡¹ {idx} ç¼ºå°‘labelå­—æ®µ")
                if "text" not in option:
                    errors.append(f"é€‰é¡¹ {idx} ç¼ºå°‘textå­—æ®µ")
    
    # æ£€æŸ¥ç­”æ¡ˆæ ¼å¼
    if "correct_answer" in question_data:
        answer = question_data["correct_answer"]
        if answer is not None:
            if answer not in ["A", "B", "C", "D"]:
                errors.append(f"ç­”æ¡ˆæ ¼å¼é”™è¯¯: {answer}ï¼ˆåº”ä¸ºA/B/C/Dï¼‰")
            # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦åœ¨é€‰é¡¹èŒƒå›´å†…
            if "options" in question_data and isinstance(question_data["options"], list):
                option_labels = [opt.get("label") for opt in question_data["options"]]
                if answer not in option_labels:
                    errors.append(f"ç­”æ¡ˆ {answer} ä¸åœ¨é€‰é¡¹èŒƒå›´å†…: {option_labels}")
    
    # æ£€æŸ¥å›¾ç‰‡è·¯å¾„
    if "question_images" in question_data:
        for img_path in question_data["question_images"]:
            if img_path:
                full_path = Path(__file__).parent.parent / img_path
                if not full_path.exists():
                    errors.append(f"é¢˜ç›®å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
    
    if "options" in question_data:
        for option in question_data["options"]:
            if isinstance(option, dict) and option.get("image"):
                img_path = option["image"]
                if img_path:
                    full_path = Path(__file__).parent.parent / img_path
                    if not full_path.exists():
                        errors.append(f"é€‰é¡¹å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
    
    return len(errors) == 0, errors

def clean_question_file(question_file: Path) -> Tuple[Dict, Dict]:
    """æ¸…æ´—å•ä¸ªé¢˜ç›®æ–‡ä»¶
    
    Returns:
        (cleaned_question_data, translation_data): æ¸…æ´—åçš„é¢˜ç›®æ•°æ®å’Œç¿»è¯‘æ•°æ®
    """
    with open(question_file, "r", encoding="utf-8") as f:
        question_data = json.load(f)
    
    # æ¸…æ´—é¢˜ç›®æ–‡æœ¬
    if "question_text" in question_data:
        original_text = question_data["question_text"]
        english_text, translation_text = separate_bilingual_text(original_text)
        question_data["question_text"] = english_text
        
        # æå–ç¿»è¯‘ï¼ˆå¦‚æœæœ‰ä¸­æ–‡ï¼‰
        chinese_translation = extract_translation_from_text(original_text)
    
    # æ¸…æ´—é€‰é¡¹æ–‡æœ¬
    translation_options = {}
    if "options" in question_data:
        for option in question_data["options"]:
            if "text" in option:
                original_option_text = option["text"]
                english_option_text, _ = separate_bilingual_text(original_option_text)
                option["text"] = english_option_text
                
                # æå–é€‰é¡¹ç¿»è¯‘ï¼ˆå¦‚æœæœ‰ä¸­æ–‡ï¼‰
                option_label = option.get("label", "")
                chinese_option = extract_translation_from_text(original_option_text)
                if chinese_option and option_label:
                    translation_options[option_label] = chinese_option
    
    # æ„å»ºç¿»è¯‘æ•°æ®
    translation_data = {}
    question_id = question_data.get("id", "")
    if chinese_translation or translation_options:
        translation_data = {
            "question": chinese_translation,
            "options": translation_options
        }
    
    return question_data, translation_data

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§¹ KPPé¢˜ç›®æ•°æ®æ¸…æ´—å·¥å…·")
    print("=" * 60)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    QUESTIONS_DIR.mkdir(parents=True, exist_ok=True)
    TRANSLATIONS_DIR.mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰é¢˜ç›®æ–‡ä»¶
    question_files = sorted(QUESTIONS_DIR.glob("part-*-question-*.json"))
    
    if not question_files:
        print("âš ï¸  æœªæ‰¾åˆ°é¢˜ç›®æ–‡ä»¶")
        return
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(question_files)} ä¸ªé¢˜ç›®æ–‡ä»¶")
    
    # ç»Ÿè®¡æ•°æ®
    total_questions = 0
    cleaned_questions = 0
    errors_count = 0
    translations = {}
    
    # å¤„ç†æ¯ä¸ªé¢˜ç›®æ–‡ä»¶
    for question_file in question_files:
        try:
            print(f"\nğŸ“ å¤„ç†: {question_file.name}")
            
            # æ¸…æ´—é¢˜ç›®æ•°æ®
            cleaned_data, translation_data = clean_question_file(question_file)
            
            # éªŒè¯æ•°æ®
            is_valid, errors = validate_question_data(cleaned_data)
            
            if not is_valid:
                print(f"  âš ï¸  æ•°æ®éªŒè¯å¤±è´¥:")
                for error in errors:
                    print(f"    - {error}")
                errors_count += 1
                continue
            
            # ä¿å­˜æ¸…æ´—åçš„æ•°æ®ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
            with open(question_file, "w", encoding="utf-8") as f:
                json.dump(cleaned_data, f, indent=2, ensure_ascii=False)
            
            # æ”¶é›†ç¿»è¯‘æ•°æ®
            question_id = cleaned_data.get("id", "")
            if translation_data and (translation_data.get("question") or translation_data.get("options")):
                translations[question_id] = translation_data
            
            cleaned_questions += 1
            total_questions += 1
            print(f"  âœ“ æ¸…æ´—å®Œæˆ")
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            errors_count += 1
            import traceback
            traceback.print_exc()
    
    # ç”Ÿæˆç¿»è¯‘æ•°æ®æ–‡ä»¶
    if translations:
        translation_file = TRANSLATIONS_DIR / "zh.json"
        translation_output = {
            "questions": translations
        }
        with open(translation_file, "w", encoding="utf-8") as f:
            json.dump(translation_output, f, indent=2, ensure_ascii=False)
        print(f"\nâœ“ ç¿»è¯‘æ•°æ®å·²ä¿å­˜: {translation_file}")
        print(f"  åŒ…å« {len(translations)} ä¸ªé¢˜ç›®çš„ç¿»è¯‘")
    else:
        print("\nâš ï¸  æœªæ‰¾åˆ°ç¿»è¯‘æ•°æ®ï¼ˆå¯èƒ½é¢˜ç›®ä¸­æ²¡æœ‰ä¸­æ–‡ï¼‰")
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¸…æ´—ç»Ÿè®¡:")
    print(f"  æ€»é¢˜ç›®æ•°: {total_questions}")
    print(f"  æˆåŠŸæ¸…æ´—: {cleaned_questions}")
    print(f"  é”™è¯¯æ•°é‡: {errors_count}")
    print(f"  ç¿»è¯‘æ•°æ®: {len(translations)} ä¸ªé¢˜ç›®")
    print("=" * 60)

if __name__ == "__main__":
    main()
