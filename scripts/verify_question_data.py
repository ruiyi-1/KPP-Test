#!/usr/bin/env python3
"""
éªŒè¯é¢˜ç›®æ•°æ®çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
æ£€æŸ¥å›¾ç‰‡ã€é¢˜ç›®æ–‡æœ¬ã€é€‰é¡¹æ˜¯å¦åŒ¹é…
"""
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from collections import defaultdict

# é…ç½®
DATA_DIR = Path(__file__).parent.parent / "data"
QUESTIONS_DIR = DATA_DIR / "questions"
FINAL_QUESTIONS_FILE = Path(__file__).parent.parent / "web" / "src" / "data" / "questions.json"
PUBLIC_DIR = Path(__file__).parent.parent / "web" / "public"

def verify_final_questions() -> Tuple[bool, List[Dict]]:
    """éªŒè¯æœ€ç»ˆé¢˜ç›®æ•°æ®"""
    if not FINAL_QUESTIONS_FILE.exists():
        print(f"âŒ æœ€ç»ˆé¢˜ç›®æ–‡ä»¶ä¸å­˜åœ¨: {FINAL_QUESTIONS_FILE}")
        return False, []
    
    with open(FINAL_QUESTIONS_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    questions = data.get("questions", [])
    print(f"ğŸ“Š æ€»é¢˜ç›®æ•°: {len(questions)}")
    
    issues = []
    image_usage = defaultdict(list)  # å›¾ç‰‡è·¯å¾„ -> ä½¿ç”¨è¯¥å›¾ç‰‡çš„é¢˜ç›®IDåˆ—è¡¨
    
    # æ£€æŸ¥æ¯ä¸ªé¢˜ç›®
    for idx, question in enumerate(questions):
        question_id = question.get("id", f"question-{idx}")
        question_issues = []
        
        # æ£€æŸ¥åŸºæœ¬å­—æ®µ
        if not question.get("question"):
            question_issues.append("ç¼ºå°‘é¢˜ç›®æ–‡æœ¬")
        if not question.get("options") or len(question["options"]) < 2:
            question_issues.append(f"é€‰é¡¹æ•°é‡ä¸è¶³: {len(question.get('options', []))}")
        if not question.get("correctAnswer"):
            question_issues.append("ç¼ºå°‘æ­£ç¡®ç­”æ¡ˆ")
        
        # æ£€æŸ¥é¢˜ç›®å›¾ç‰‡
        question_images = question.get("questionImages", [])
        if not isinstance(question_images, list):
            question_images = []
        
        for img_path in question_images:
            if not img_path:
                continue
            
            # è®°å½•å›¾ç‰‡ä½¿ç”¨æƒ…å†µ
            image_usage[img_path].append(question_id)
            
            # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            clean_path = img_path.lstrip("/")
            if not clean_path.startswith("images/"):
                clean_path = f"images/{clean_path}"
            full_path = PUBLIC_DIR / clean_path
            
            if not full_path.exists():
                question_issues.append(f"é¢˜ç›®å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
        
        # æ£€æŸ¥é€‰é¡¹
        options = question.get("options", [])
        option_labels = set()
        
        for opt_idx, option in enumerate(options):
            label = option.get("label", "").strip().upper()
            
            if not label:
                question_issues.append(f"é€‰é¡¹ {opt_idx} ç¼ºå°‘æ ‡ç­¾")
            elif label in option_labels:
                question_issues.append(f"é€‰é¡¹æ ‡ç­¾é‡å¤: {label}")
            else:
                option_labels.add(label)
            
            # æ£€æŸ¥é€‰é¡¹å†…å®¹
            if option.get("type") == "text" and not option.get("content"):
                question_issues.append(f"é€‰é¡¹ {label} ç¼ºå°‘æ–‡æœ¬å†…å®¹")
            
            # æ£€æŸ¥é€‰é¡¹å›¾ç‰‡
            if option.get("type") == "image":
                img_path = option.get("imagePath")
                if not img_path:
                    question_issues.append(f"é€‰é¡¹ {label} ç±»å‹ä¸ºå›¾ç‰‡ä½†ç¼ºå°‘å›¾ç‰‡è·¯å¾„")
                else:
                    clean_path = img_path.lstrip("/")
                    if not clean_path.startswith("images/"):
                        clean_path = f"images/{clean_path}"
                    full_path = PUBLIC_DIR / clean_path
                    
                    if not full_path.exists():
                        question_issues.append(f"é€‰é¡¹ {label} å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
        
        # æ£€æŸ¥æ­£ç¡®ç­”æ¡ˆæ˜¯å¦åœ¨é€‰é¡¹ä¸­
        correct_answer = question.get("correctAnswer", "").strip().upper()
        if correct_answer and correct_answer not in option_labels:
            question_issues.append(f"æ­£ç¡®ç­”æ¡ˆ '{correct_answer}' ä¸åœ¨é€‰é¡¹ä¸­")
        
        if question_issues:
            issues.append({
                "question_id": question_id,
                "index": idx,
                "issues": question_issues
            })
    
    # æ£€æŸ¥å›¾ç‰‡é‡å¤ä½¿ç”¨ï¼ˆå¯èƒ½çš„é—®é¢˜ï¼‰
    duplicate_images = {img: qids for img, qids in image_usage.items() if len(qids) > 1}
    if duplicate_images:
        print(f"\nâš ï¸  å‘ç° {len(duplicate_images)} ä¸ªå›¾ç‰‡è¢«å¤šä¸ªé¢˜ç›®ä½¿ç”¨:")
        for img, qids in list(duplicate_images.items())[:10]:
            print(f"  {img}: è¢« {len(qids)} ä¸ªé¢˜ç›®ä½¿ç”¨")
            print(f"    ç¤ºä¾‹: {', '.join(qids[:3])}")
            if len(qids) > 3:
                print(f"    ... è¿˜æœ‰ {len(qids) - 3} ä¸ª")
        if len(duplicate_images) > 10:
            print(f"  ... è¿˜æœ‰ {len(duplicate_images) - 10} ä¸ªé‡å¤å›¾ç‰‡")
    
    return len(issues) == 0, issues

def verify_original_questions() -> Dict[str, Dict]:
    """åŠ è½½å¹¶éªŒè¯åŸå§‹é¢˜ç›®æ•°æ®"""
    original_questions = {}
    
    if not QUESTIONS_DIR.exists():
        print(f"âš ï¸  åŸå§‹é¢˜ç›®ç›®å½•ä¸å­˜åœ¨: {QUESTIONS_DIR}")
        return original_questions
    
    question_files = sorted(QUESTIONS_DIR.glob("part-*-question-*.json"))
    print(f"ğŸ“‚ æ‰¾åˆ° {len(question_files)} ä¸ªåŸå§‹é¢˜ç›®æ–‡ä»¶")
    
    for question_file in question_files:
        try:
            with open(question_file, "r", encoding="utf-8") as f:
                question_data = json.load(f)
            
            question_id = question_data.get("id", "")
            if question_id:
                original_questions[question_id] = question_data
        except Exception as e:
            print(f"  âš ï¸  è¯»å–å¤±è´¥ {question_file.name}: {e}")
    
    return original_questions

def normalize_text(text: str) -> str:
    """æ ‡å‡†åŒ–æ–‡æœ¬ç”¨äºæ¯”è¾ƒ"""
    if not text:
        return ""
    # ç§»é™¤å¤šä½™ç©ºæ ¼ã€æ ‡ç‚¹ç¬¦å·ï¼Œç»Ÿä¸€å¤§å°å†™
    text = text.strip().lower()
    # ç§»é™¤å¸¸è§çš„æ ‡ç‚¹ç¬¦å·å·®å¼‚
    text = text.replace("?", "").replace("!", "").replace(".", "").replace(",", "")
    # ç»Ÿä¸€ç©ºæ ¼
    text = " ".join(text.split())
    return text

def calculate_question_hash(question_data: Dict, use_original_format: bool = False) -> str:
    """è®¡ç®—é¢˜ç›®çš„å“ˆå¸Œå€¼ï¼Œç”¨äºåŒ¹é…"""
    if use_original_format:
        # åŸå§‹æ ¼å¼
        question_text = normalize_text(question_data.get("question_text", ""))
        option_texts = []
        for option in sorted(question_data.get("options", []), key=lambda x: x.get("label", "")):
            option_texts.append(normalize_text(option.get("text", "")))
    else:
        # æœ€ç»ˆæ ¼å¼
        question_text = normalize_text(question_data.get("question", ""))
        option_texts = []
        for option in sorted(question_data.get("options", []), key=lambda x: x.get("label", "")):
            option_texts.append(normalize_text(option.get("content", "")))
    
    # ç»„åˆé¢˜ç›®æ–‡æœ¬å’Œæ‰€æœ‰é€‰é¡¹æ–‡æœ¬
    key_parts = [question_text] + option_texts
    key_string = "|".join(key_parts)
    return hashlib.md5(key_string.encode("utf-8")).hexdigest()

def calculate_question_hash_flexible(question_data: Dict, use_original_format: bool = False) -> Tuple[str, str]:
    """è®¡ç®—é¢˜ç›®çš„å¤šä¸ªå“ˆå¸Œå€¼ï¼Œç”¨äºçµæ´»åŒ¹é…
    è¿”å›: (å®Œæ•´hash, ä»…é¢˜ç›®æ–‡æœ¬hash)
    """
    if use_original_format:
        question_text = normalize_text(question_data.get("question_text", ""))
    else:
        question_text = normalize_text(question_data.get("question", ""))
    
    # ä»…é¢˜ç›®æ–‡æœ¬çš„hash
    question_only_hash = hashlib.md5(question_text.encode("utf-8")).hexdigest()
    
    # å®Œæ•´hashï¼ˆé¢˜ç›®+é€‰é¡¹ï¼‰
    full_hash = calculate_question_hash(question_data, use_original_format)
    
    return full_hash, question_only_hash

def match_and_compare(original_questions: Dict[str, Dict], final_questions: List[Dict]) -> Tuple[List[Dict], List[Dict]]:
    """åŒ¹é…åŸå§‹é¢˜ç›®å’Œæœ€ç»ˆé¢˜ç›®ï¼Œå¹¶æ¯”è¾ƒå·®å¼‚
    è¿”å›: (åŒ¹é…ç»“æœåˆ—è¡¨, é—®é¢˜åˆ—è¡¨)
    """
    if not original_questions:
        return [], []
    
    # ä¸ºåŸå§‹é¢˜ç›®å»ºç«‹å¤šä¸ªå“ˆå¸Œç´¢å¼•
    original_by_full_hash = {}  # å®Œæ•´hash -> é¢˜ç›®åˆ—è¡¨
    original_by_question_hash = {}  # ä»…é¢˜ç›®æ–‡æœ¬hash -> é¢˜ç›®åˆ—è¡¨
    
    for orig_id, orig_data in original_questions.items():
        full_hash, question_hash = calculate_question_hash_flexible(orig_data, use_original_format=True)
        
        if full_hash not in original_by_full_hash:
            original_by_full_hash[full_hash] = []
        original_by_full_hash[full_hash].append((orig_id, orig_data))
        
        if question_hash not in original_by_question_hash:
            original_by_question_hash[question_hash] = []
        original_by_question_hash[question_hash].append((orig_id, orig_data))
    
    matches = []
    comparison_issues = []
    matched_original_ids = set()
    matched_final_ids = set()
    
    # åŒ¹é…æœ€ç»ˆé¢˜ç›®
    for final_question in final_questions:
        final_id = final_question.get("id", "")
        full_hash, question_hash = calculate_question_hash_flexible(final_question, use_original_format=False)
        
        matched = False
        
        # é¦–å…ˆå°è¯•å®Œæ•´åŒ¹é…
        if full_hash in original_by_full_hash:
            for orig_id, orig_data in original_by_full_hash[full_hash]:
                matches.append({
                    "original_id": orig_id,
                    "final_id": final_id,
                    "match_type": "å®Œæ•´åŒ¹é…",
                    "original": orig_data,
                    "final": final_question
                })
                matched_original_ids.add(orig_id)
                matched_final_ids.add(final_id)
                matched = True
                
                # æ¯”è¾ƒå›¾ç‰‡
                issues = compare_question_pair(orig_data, final_question, orig_id, final_id)
                if issues:
                    comparison_issues.extend(issues)
        
        # å¦‚æœå®Œæ•´åŒ¹é…å¤±è´¥ï¼Œå°è¯•ä»…é¢˜ç›®æ–‡æœ¬åŒ¹é…ï¼ˆå¯èƒ½é€‰é¡¹æœ‰å˜åŒ–ï¼‰
        if not matched and question_hash in original_by_question_hash:
            for orig_id, orig_data in original_by_question_hash[question_hash]:
                # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ¹é…è¿‡
                if orig_id in matched_original_ids:
                    continue
                
                matches.append({
                    "original_id": orig_id,
                    "final_id": final_id,
                    "match_type": "é¢˜ç›®æ–‡æœ¬åŒ¹é…ï¼ˆé€‰é¡¹å¯èƒ½ä¸åŒï¼‰",
                    "original": orig_data,
                    "final": final_question
                })
                matched_original_ids.add(orig_id)
                matched_final_ids.add(final_id)
                
                # æ¯”è¾ƒå›¾ç‰‡å’Œé€‰é¡¹
                issues = compare_question_pair(orig_data, final_question, orig_id, final_id)
                if issues:
                    comparison_issues.extend(issues)
    
    return matches, comparison_issues

def compare_question_pair(orig_data: Dict, final_data: Dict, orig_id: str, final_id: str) -> List[Dict]:
    """æ¯”è¾ƒä¸€å¯¹åŒ¹é…çš„é¢˜ç›®"""
    issues = []
    
    # æ¯”è¾ƒé¢˜ç›®å›¾ç‰‡
    orig_images = orig_data.get("question_images", [])
    final_images = final_data.get("questionImages", [])
    
    def normalize_img_path(path):
        if not path:
            return ""
        path = str(path).lstrip("/")
        if path.startswith("images/"):
            path = path[7:]
        return path.lower()
    
    orig_normalized = sorted([normalize_img_path(img) for img in orig_images if img])
    final_normalized = sorted([normalize_img_path(img) for img in final_images if img])
    
    if orig_normalized != final_normalized:
        issues.append({
            "original_id": orig_id,
            "final_id": final_id,
            "type": "é¢˜ç›®å›¾ç‰‡ä¸ä¸€è‡´",
            "original_images": orig_images,
            "final_images": final_images,
            "original_normalized": orig_normalized,
            "final_normalized": final_normalized
        })
    
    # æ¯”è¾ƒé€‰é¡¹å›¾ç‰‡
    orig_options = orig_data.get("options", [])
    final_options = final_data.get("options", [])
    
    orig_by_label = {opt.get("label", ""): opt for opt in orig_options}
    final_by_label = {opt.get("label", ""): opt for opt in final_options}
    
    all_labels = set(orig_by_label.keys()) | set(final_by_label.keys())
    
    for label in sorted(all_labels):
        orig_opt = orig_by_label.get(label)
        final_opt = final_by_label.get(label)
        
        if not orig_opt or not final_opt:
            continue
        
        orig_img = normalize_img_path(orig_opt.get("image")) if orig_opt.get("image") else ""
        final_img = normalize_img_path(final_opt.get("imagePath")) if final_opt.get("imagePath") else ""
        
        if orig_img != final_img:
            issues.append({
                "original_id": orig_id,
                "final_id": final_id,
                "type": f"é€‰é¡¹ {label} å›¾ç‰‡ä¸ä¸€è‡´",
                "original_image": orig_opt.get("image"),
                "final_image": final_opt.get("imagePath")
            })
    
    return issues

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” éªŒè¯é¢˜ç›®æ•°æ®å®Œæ•´æ€§å’Œæ­£ç¡®æ€§")
    print("=" * 60)
    
    # éªŒè¯æœ€ç»ˆé¢˜ç›®æ•°æ®
    print("\nğŸ“‹ éªŒè¯æœ€ç»ˆé¢˜ç›®æ•°æ®...")
    is_valid, issues = verify_final_questions()
    
    if is_valid:
        print("âœ… æ‰€æœ‰é¢˜ç›®æ•°æ®éªŒè¯é€šè¿‡")
    else:
        print(f"âŒ å‘ç° {len(issues)} ä¸ªé¢˜ç›®å­˜åœ¨é—®é¢˜")
        print("\né—®é¢˜è¯¦æƒ…ï¼ˆå‰10ä¸ªï¼‰:")
        for issue_data in issues[:10]:
            print(f"\né¢˜ç›® ID: {issue_data['question_id']} (ç´¢å¼•: {issue_data['index']})")
            for issue in issue_data['issues']:
                print(f"  - {issue}")
        if len(issues) > 10:
            print(f"\n... è¿˜æœ‰ {len(issues) - 10} ä¸ªé¢˜ç›®å­˜åœ¨é—®é¢˜")
    
    # åŠ è½½åŸå§‹é¢˜ç›®æ•°æ®
    print("\nğŸ“‚ åŠ è½½åŸå§‹é¢˜ç›®æ•°æ®...")
    original_questions = verify_original_questions()
    
    if original_questions:
        print(f"âœ“ æ‰¾åˆ° {len(original_questions)} é“åŸå§‹é¢˜ç›®")
        
        # åŠ è½½æœ€ç»ˆé¢˜ç›®æ•°æ®
        with open(FINAL_QUESTIONS_FILE, "r", encoding="utf-8") as f:
            final_data = json.load(f)
        final_questions = final_data.get("questions", [])
        
        # åŒ¹é…å¹¶æ¯”è¾ƒ
        print("\nğŸ”— é€šè¿‡é¢˜ç›®hashåŒ¹é…å¹¶æ¯”è¾ƒåŸå§‹é¢˜ç›®å’Œæœ€ç»ˆé¢˜ç›®...")
        matches, comparison_issues = match_and_compare(original_questions, final_questions)
        
        print(f"âœ“ åŒ¹é…åˆ° {len(matches)} å¯¹é¢˜ç›®")
        
        if matches:
            print("\nåŒ¹é…è¯¦æƒ…:")
            for match in matches[:10]:
                print(f"  {match['original_id']} <-> {match['final_id']} ({match['match_type']})")
            if len(matches) > 10:
                print(f"  ... è¿˜æœ‰ {len(matches) - 10} å¯¹åŒ¹é…")
        
        if comparison_issues:
            print(f"\nâš ï¸  å‘ç° {len(comparison_issues)} ä¸ªåŒ¹é…é¢˜ç›®çš„å›¾ç‰‡ä¸ä¸€è‡´:")
            for comp_issue in comparison_issues[:10]:
                print(f"\nåŸå§‹ID: {comp_issue['original_id']} -> æœ€ç»ˆID: {comp_issue['final_id']}")
                print(f"  é—®é¢˜ç±»å‹: {comp_issue['type']}")
                if 'original_images' in comp_issue:
                    print(f"  åŸå§‹å›¾ç‰‡: {comp_issue['original_images']}")
                    print(f"  æœ€ç»ˆå›¾ç‰‡: {comp_issue['final_images']}")
                elif 'original_image' in comp_issue:
                    print(f"  åŸå§‹å›¾ç‰‡: {comp_issue['original_image']}")
                    print(f"  æœ€ç»ˆå›¾ç‰‡: {comp_issue['final_image']}")
            if len(comparison_issues) > 10:
                print(f"\n  ... è¿˜æœ‰ {len(comparison_issues) - 10} ä¸ªé—®é¢˜")
        else:
            if matches:
                print("âœ… æ‰€æœ‰åŒ¹é…é¢˜ç›®çš„å›¾ç‰‡ä¸€è‡´")
            else:
                print("âš ï¸  æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•é¢˜ç›®")
    else:
        print("âš ï¸  æ²¡æœ‰åŸå§‹é¢˜ç›®æ•°æ®ï¼Œè·³è¿‡æ¯”è¾ƒ")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š éªŒè¯ç»Ÿè®¡")
    print("=" * 60)
    
    if FINAL_QUESTIONS_FILE.exists():
        with open(FINAL_QUESTIONS_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        questions = data.get("questions", [])
        
        # ç»Ÿè®¡å›¾ç‰‡
        total_question_images = 0
        total_option_images = 0
        missing_question_images = 0
        missing_option_images = 0
        
        for q in questions:
            for img in q.get("questionImages", []):
                total_question_images += 1
                clean_path = img.lstrip("/")
                if not clean_path.startswith("images/"):
                    clean_path = f"images/{clean_path}"
                if not (PUBLIC_DIR / clean_path).exists():
                    missing_question_images += 1
            
            for opt in q.get("options", []):
                if opt.get("imagePath"):
                    total_option_images += 1
                    clean_path = opt["imagePath"].lstrip("/")
                    if not clean_path.startswith("images/"):
                        clean_path = f"images/{clean_path}"
                    if not (PUBLIC_DIR / clean_path).exists():
                        missing_option_images += 1
        
        print(f"æ€»é¢˜ç›®æ•°: {len(questions)}")
        print(f"é¢˜ç›®å›¾ç‰‡: {total_question_images} ä¸ªå¼•ç”¨, {missing_question_images} ä¸ªç¼ºå¤±")
        print(f"é€‰é¡¹å›¾ç‰‡: {total_option_images} ä¸ªå¼•ç”¨, {missing_option_images} ä¸ªç¼ºå¤±")
    
    print("=" * 60)
    
    return is_valid and len(issues) == 0

if __name__ == "__main__":
    main()
