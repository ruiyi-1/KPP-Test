#!/usr/bin/env python3
"""
é€šè¿‡é¢˜ç›®hashéªŒè¯å›¾ç‰‡ä¸€è‡´æ€§
å³ä½¿æ²¡æœ‰åŸå§‹æ•°æ®ï¼Œä¹Ÿèƒ½æ£€æŸ¥æœ€ç»ˆæ•°æ®ä¸­ç›¸åŒhashçš„é¢˜ç›®æ˜¯å¦ä½¿ç”¨ç›¸åŒå›¾ç‰‡
"""
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Set
from collections import defaultdict

# é…ç½®
FINAL_QUESTIONS_FILE = Path(__file__).parent.parent / "web" / "src" / "data" / "questions.json"
PUBLIC_DIR = Path(__file__).parent.parent / "web" / "public"
QUESTIONS_DIR = Path(__file__).parent.parent / "data" / "questions"

def normalize_text(text: str) -> str:
    """æ ‡å‡†åŒ–æ–‡æœ¬ç”¨äºæ¯”è¾ƒ"""
    if not text:
        return ""
    text = text.strip().lower()
    # ç§»é™¤å¸¸è§çš„æ ‡ç‚¹ç¬¦å·å·®å¼‚
    text = text.replace("?", "").replace("!", "").replace(".", "").replace(",", "")
    # ç»Ÿä¸€ç©ºæ ¼
    text = " ".join(text.split())
    return text

def calculate_question_hash(question_data: Dict, use_original_format: bool = False) -> str:
    """è®¡ç®—é¢˜ç›®çš„å“ˆå¸Œå€¼"""
    if use_original_format:
        question_text = normalize_text(question_data.get("question_text", ""))
        option_texts = []
        for option in sorted(question_data.get("options", []), key=lambda x: x.get("label", "")):
            option_texts.append(normalize_text(option.get("text", "")))
    else:
        question_text = normalize_text(question_data.get("question", ""))
        option_texts = []
        for option in sorted(question_data.get("options", []), key=lambda x: x.get("label", "")):
            option_texts.append(normalize_text(option.get("content", "")))
    
    key_parts = [question_text] + option_texts
    key_string = "|".join(key_parts)
    return hashlib.md5(key_string.encode("utf-8")).hexdigest()

def normalize_image_path(path: str) -> str:
    """æ ‡å‡†åŒ–å›¾ç‰‡è·¯å¾„"""
    if not path:
        return ""
    path = str(path).lstrip("/")
    if path.startswith("images/"):
        path = path[7:]
    return path.lower()

def verify_by_hash():
    """é€šè¿‡hashéªŒè¯é¢˜ç›®æ•°æ®"""
    print("=" * 60)
    print("ğŸ” é€šè¿‡é¢˜ç›®hashéªŒè¯å›¾ç‰‡ä¸€è‡´æ€§")
    print("=" * 60)
    
    # åŠ è½½æœ€ç»ˆé¢˜ç›®æ•°æ®
    if not FINAL_QUESTIONS_FILE.exists():
        print(f"âŒ é¢˜ç›®æ–‡ä»¶ä¸å­˜åœ¨: {FINAL_QUESTIONS_FILE}")
        return
    
    with open(FINAL_QUESTIONS_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    questions = data.get("questions", [])
    print(f"\nğŸ“Š æ€»é¢˜ç›®æ•°: {len(questions)}")
    
    # æŒ‰hashåˆ†ç»„é¢˜ç›®
    questions_by_hash = defaultdict(list)
    for question in questions:
        hash_key = calculate_question_hash(question, use_original_format=False)
        questions_by_hash[hash_key].append(question)
    
    # æ‰¾å‡ºé‡å¤çš„é¢˜ç›®ï¼ˆç›¸åŒhashï¼‰
    duplicate_questions = {h: qs for h, qs in questions_by_hash.items() if len(qs) > 1}
    print(f"ğŸ“‹ å”¯ä¸€é¢˜ç›®hashæ•°: {len(questions_by_hash)}")
    print(f"ğŸ”„ é‡å¤é¢˜ç›®hashæ•°: {len(duplicate_questions)}")
    
    # æ£€æŸ¥ç›¸åŒhashçš„é¢˜ç›®æ˜¯å¦ä½¿ç”¨ç›¸åŒå›¾ç‰‡
    print("\nğŸ” æ£€æŸ¥ç›¸åŒhashé¢˜ç›®çš„å›¾ç‰‡ä¸€è‡´æ€§...")
    image_inconsistencies = []
    
    for hash_key, hash_questions in duplicate_questions.items():
        # æ”¶é›†æ‰€æœ‰å›¾ç‰‡
        all_question_images = []
        all_option_images = defaultdict(list)  # label -> images
        
        for q in hash_questions:
            # é¢˜ç›®å›¾ç‰‡
            q_images = [normalize_image_path(img) for img in q.get("questionImages", []) if img]
            all_question_images.append((q.get("id", ""), sorted(q_images)))
            
            # é€‰é¡¹å›¾ç‰‡
            for opt in q.get("options", []):
                label = opt.get("label", "")
                if opt.get("imagePath"):
                    img = normalize_image_path(opt.get("imagePath"))
                    all_option_images[label].append((q.get("id", ""), img))
        
        # æ£€æŸ¥é¢˜ç›®å›¾ç‰‡æ˜¯å¦ä¸€è‡´
        if len(set(tuple(imgs) for _, imgs in all_question_images)) > 1:
            image_inconsistencies.append({
                "hash": hash_key,
                "type": "é¢˜ç›®å›¾ç‰‡ä¸ä¸€è‡´",
                "questions": [qid for qid, _ in all_question_images],
                "images": {qid: imgs for qid, imgs in all_question_images}
            })
        
        # æ£€æŸ¥é€‰é¡¹å›¾ç‰‡æ˜¯å¦ä¸€è‡´
        for label, opt_images in all_option_images.items():
            unique_images = set(img for _, img in opt_images)
            if len(unique_images) > 1:
                image_inconsistencies.append({
                    "hash": hash_key,
                    "type": f"é€‰é¡¹ {label} å›¾ç‰‡ä¸ä¸€è‡´",
                    "questions": list(set(qid for qid, _ in opt_images)),
                    "images": {qid: img for qid, img in opt_images if qid in [q.get("id", "") for q in hash_questions]}
                })
    
    # åŠ è½½åŸå§‹é¢˜ç›®æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
    print("\nğŸ“‚ åŠ è½½åŸå§‹é¢˜ç›®æ•°æ®...")
    original_questions = {}
    if QUESTIONS_DIR.exists():
        question_files = sorted(QUESTIONS_DIR.glob("part-*-question-*.json"))
        print(f"  æ‰¾åˆ° {len(question_files)} ä¸ªåŸå§‹é¢˜ç›®æ–‡ä»¶")
        
        for question_file in question_files:
            try:
                with open(question_file, "r", encoding="utf-8") as f:
                    question_data = json.load(f)
                question_id = question_data.get("id", "")
                if question_id:
                    original_questions[question_id] = question_data
            except Exception as e:
                print(f"  âš ï¸  è¯»å–å¤±è´¥ {question_file.name}: {e}")
    
    # åŒ¹é…åŸå§‹é¢˜ç›®å’Œæœ€ç»ˆé¢˜ç›®
    matches = []
    comparison_issues = []
    
    if original_questions:
        print(f"\nğŸ”— åŒ¹é…åŸå§‹é¢˜ç›®å’Œæœ€ç»ˆé¢˜ç›®...")
        
        # ä¸ºåŸå§‹é¢˜ç›®å»ºç«‹hashç´¢å¼•
        original_by_hash = {}
        for orig_id, orig_data in original_questions.items():
            hash_key = calculate_question_hash(orig_data, use_original_format=True)
            if hash_key not in original_by_hash:
                original_by_hash[hash_key] = []
            original_by_hash[hash_key].append((orig_id, orig_data))
        
        # åŒ¹é…æœ€ç»ˆé¢˜ç›®
        for final_question in questions:
            final_id = final_question.get("id", "")
            hash_key = calculate_question_hash(final_question, use_original_format=False)
            
            if hash_key in original_by_hash:
                for orig_id, orig_data in original_by_hash[hash_key]:
                    matches.append({
                        "original_id": orig_id,
                        "final_id": final_id,
                        "original": orig_data,
                        "final": final_question
                    })
                    
                    # æ¯”è¾ƒå›¾ç‰‡
                    orig_q_images = sorted([normalize_image_path(img) for img in orig_data.get("question_images", []) if img])
                    final_q_images = sorted([normalize_image_path(img) for img in final_question.get("questionImages", []) if img])
                    
                    if orig_q_images != final_q_images:
                        comparison_issues.append({
                            "original_id": orig_id,
                            "final_id": final_id,
                            "type": "é¢˜ç›®å›¾ç‰‡ä¸ä¸€è‡´",
                            "original_images": orig_data.get("question_images", []),
                            "final_images": final_question.get("questionImages", [])
                        })
                    
                    # æ¯”è¾ƒé€‰é¡¹å›¾ç‰‡
                    orig_options = {opt.get("label", ""): opt for opt in orig_data.get("options", [])}
                    final_options = {opt.get("label", ""): opt for opt in final_question.get("options", [])}
                    
                    for label in set(orig_options.keys()) | set(final_options.keys()):
                        orig_opt = orig_options.get(label)
                        final_opt = final_options.get(label)
                        
                        if orig_opt and final_opt:
                            orig_img = normalize_image_path(orig_opt.get("image", "")) if orig_opt.get("image") else ""
                            final_img = normalize_image_path(final_opt.get("imagePath", "")) if final_opt.get("imagePath") else ""
                            
                            if orig_img != final_img:
                                comparison_issues.append({
                                    "original_id": orig_id,
                                    "final_id": final_id,
                                    "type": f"é€‰é¡¹ {label} å›¾ç‰‡ä¸ä¸€è‡´",
                                    "original_image": orig_opt.get("image"),
                                    "final_image": final_opt.get("imagePath")
                                })
        
        print(f"  âœ“ åŒ¹é…åˆ° {len(matches)} å¯¹é¢˜ç›®")
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š éªŒè¯ç»“æœ")
    print("=" * 60)
    
    if image_inconsistencies:
        print(f"\nâŒ å‘ç° {len(image_inconsistencies)} ä¸ªç›¸åŒhashé¢˜ç›®çš„å›¾ç‰‡ä¸ä¸€è‡´é—®é¢˜:")
        for issue in image_inconsistencies[:10]:
            print(f"\n  Hash: {issue['hash'][:16]}...")
            print(f"  é—®é¢˜ç±»å‹: {issue['type']}")
            print(f"  æ¶‰åŠé¢˜ç›®: {', '.join(issue['questions'][:5])}")
            if len(issue['questions']) > 5:
                print(f"    ... è¿˜æœ‰ {len(issue['questions']) - 5} ä¸ªé¢˜ç›®")
            if 'images' in issue:
                print("  å›¾ç‰‡å·®å¼‚:")
                for qid, imgs in list(issue['images'].items())[:3]:
                    print(f"    {qid}: {imgs}")
        if len(image_inconsistencies) > 10:
            print(f"\n  ... è¿˜æœ‰ {len(image_inconsistencies) - 10} ä¸ªé—®é¢˜")
    else:
        print("\nâœ… ç›¸åŒhashçš„é¢˜ç›®å›¾ç‰‡éƒ½ä¸€è‡´")
    
    if comparison_issues:
        print(f"\nâš ï¸  åŸå§‹é¢˜ç›®å’Œæœ€ç»ˆé¢˜ç›®æ¯”è¾ƒï¼Œå‘ç° {len(comparison_issues)} ä¸ªå›¾ç‰‡ä¸ä¸€è‡´:")
        for issue in comparison_issues[:10]:
            print(f"\n  {issue['original_id']} <-> {issue['final_id']}")
            print(f"  é—®é¢˜: {issue['type']}")
            if 'original_images' in issue:
                print(f"  åŸå§‹å›¾ç‰‡: {issue['original_images']}")
                print(f"  æœ€ç»ˆå›¾ç‰‡: {issue['final_images']}")
            elif 'original_image' in issue:
                print(f"  åŸå§‹å›¾ç‰‡: {issue['original_image']}")
                print(f"  æœ€ç»ˆå›¾ç‰‡: {issue['final_image']}")
        if len(comparison_issues) > 10:
            print(f"\n  ... è¿˜æœ‰ {len(comparison_issues) - 10} ä¸ªé—®é¢˜")
    elif matches:
        print("\nâœ… æ‰€æœ‰åŒ¹é…é¢˜ç›®çš„å›¾ç‰‡éƒ½ä¸€è‡´")
    
    # ç»Ÿè®¡å›¾ç‰‡é‡å¤ä½¿ç”¨
    print("\n" + "=" * 60)
    print("ğŸ“¸ å›¾ç‰‡ä½¿ç”¨ç»Ÿè®¡")
    print("=" * 60)
    
    image_usage = defaultdict(list)
    for question in questions:
        qid = question.get("id", "")
        for img in question.get("questionImages", []):
            if img:
                image_usage[img].append(qid)
        for opt in question.get("options", []):
            if opt.get("imagePath"):
                image_usage[opt["imagePath"]].append(qid)
    
    duplicate_images = {img: qids for img, qids in image_usage.items() if len(qids) > 1}
    high_usage_images = {img: qids for img, qids in duplicate_images.items() if len(qids) > 10}
    
    print(f"æ€»å›¾ç‰‡å¼•ç”¨æ•°: {sum(len(qids) for qids in image_usage.values())}")
    print(f"å”¯ä¸€å›¾ç‰‡æ•°: {len(image_usage)}")
    print(f"è¢«å¤šä¸ªé¢˜ç›®ä½¿ç”¨çš„å›¾ç‰‡: {len(duplicate_images)}")
    print(f"è¢«è¶…è¿‡10ä¸ªé¢˜ç›®ä½¿ç”¨çš„å›¾ç‰‡: {len(high_usage_images)}")
    
    if high_usage_images:
        print("\nâš ï¸  è¢«å¤§é‡ä½¿ç”¨çš„å›¾ç‰‡ï¼ˆå¯èƒ½æœ‰é—®é¢˜ï¼‰:")
        for img, qids in list(high_usage_images.items())[:5]:
            print(f"  {img}: {len(qids)} ä¸ªé¢˜ç›®")
            # æ£€æŸ¥è¿™äº›é¢˜ç›®æ˜¯å¦çœŸçš„åº”è¯¥ä½¿ç”¨ç›¸åŒå›¾ç‰‡
            question_texts = set()
            for q in questions:
                if q.get("id", "") in qids:
                    question_texts.add(normalize_text(q.get("question", ""))[:50])
            print(f"    æ¶‰åŠ {len(question_texts)} ä¸ªä¸åŒé¢˜ç›®æ–‡æœ¬")
            if len(question_texts) > 1:
                print(f"    âš ï¸  è¿™äº›é¢˜ç›®æ–‡æœ¬ä¸åŒï¼Œä½†ä½¿ç”¨äº†ç›¸åŒå›¾ç‰‡ï¼Œå¯èƒ½æœ‰é—®é¢˜ï¼")
    
    print("=" * 60)

if __name__ == "__main__":
    verify_by_hash()
