#!/usr/bin/env python3
"""
ç”Ÿæˆè¯¦ç»†çš„é¢˜ç›®æ•°æ®éªŒè¯æŠ¥å‘Š
åŒ…æ‹¬å›¾ç‰‡é‡å¤ä½¿ç”¨ã€ç¼ºå¤±æ–‡ä»¶ã€é¢˜ç›®é€‰é¡¹ä¸€è‡´æ€§ç­‰é—®é¢˜
"""
import json
from pathlib import Path
from typing import Dict, List, Set
from collections import defaultdict

# é…ç½®
FINAL_QUESTIONS_FILE = Path(__file__).parent.parent / "web" / "src" / "data" / "questions.json"
PUBLIC_DIR = Path(__file__).parent.parent / "web" / "public"
REPORT_FILE = Path(__file__).parent.parent / "verification_report.txt"

def generate_report():
    """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
    print("=" * 60)
    print("ğŸ“‹ ç”Ÿæˆé¢˜ç›®æ•°æ®éªŒè¯æŠ¥å‘Š")
    print("=" * 60)
    
    if not FINAL_QUESTIONS_FILE.exists():
        print(f"âŒ é¢˜ç›®æ–‡ä»¶ä¸å­˜åœ¨: {FINAL_QUESTIONS_FILE}")
        return
    
    with open(FINAL_QUESTIONS_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    questions = data.get("questions", [])
    print(f"ğŸ“Š æ€»é¢˜ç›®æ•°: {len(questions)}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    image_usage = defaultdict(list)  # å›¾ç‰‡è·¯å¾„ -> ä½¿ç”¨è¯¥å›¾ç‰‡çš„é¢˜ç›®åˆ—è¡¨
    missing_images = []  # ç¼ºå¤±çš„å›¾ç‰‡
    duplicate_image_issues = []  # å›¾ç‰‡é‡å¤ä½¿ç”¨çš„é—®é¢˜
    
    # æ£€æŸ¥æ¯ä¸ªé¢˜ç›®
    for question in questions:
        question_id = question.get("id", "")
        
        # æ£€æŸ¥é¢˜ç›®å›¾ç‰‡
        question_images = question.get("questionImages", [])
        for img_path in question_images:
            if not img_path:
                continue
            
            # è®°å½•ä½¿ç”¨æƒ…å†µ
            image_usage[img_path].append({
                "id": question_id,
                "question": question.get("question", "")[:50] + "..." if len(question.get("question", "")) > 50 else question.get("question", "")
            })
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            clean_path = img_path.lstrip("/")
            if not clean_path.startswith("images/"):
                clean_path = f"images/{clean_path}"
            full_path = PUBLIC_DIR / clean_path
            
            if not full_path.exists():
                missing_images.append({
                    "question_id": question_id,
                    "image_path": img_path,
                    "full_path": str(full_path)
                })
        
        # æ£€æŸ¥é€‰é¡¹å›¾ç‰‡
        for option in question.get("options", []):
            img_path = option.get("imagePath")
            if img_path:
                image_usage[img_path].append({
                    "id": question_id,
                    "question": f"é€‰é¡¹ {option.get('label', '')}: {option.get('content', '')[:30]}"
                })
                
                clean_path = img_path.lstrip("/")
                if not clean_path.startswith("images/"):
                    clean_path = f"images/{clean_path}"
                full_path = PUBLIC_DIR / clean_path
                
                if not full_path.exists():
                    missing_images.append({
                        "question_id": question_id,
                        "image_path": img_path,
                        "full_path": str(full_path),
                        "option": option.get("label", "")
                    })
    
    # æ‰¾å‡ºé‡å¤ä½¿ç”¨çš„å›¾ç‰‡
    for img_path, usages in image_usage.items():
        if len(usages) > 1:
            # æ£€æŸ¥è¿™äº›ä½¿ç”¨æ˜¯å¦åˆç†ï¼ˆç›¸åŒé¢˜ç›®æ–‡æœ¬å¯èƒ½åˆç†ï¼‰
            unique_questions = set()
            for usage in usages:
                unique_questions.add(usage["question"])
            
            # å¦‚æœä¸åŒé¢˜ç›®ä½¿ç”¨ç›¸åŒå›¾ç‰‡ï¼Œå¯èƒ½æœ‰é—®é¢˜
            if len(unique_questions) > 1:
                duplicate_image_issues.append({
                    "image_path": img_path,
                    "usage_count": len(usages),
                    "unique_questions": len(unique_questions),
                    "usages": usages[:5]  # åªä¿å­˜å‰5ä¸ªç¤ºä¾‹
                })
    
    # ç”ŸæˆæŠ¥å‘Š
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("é¢˜ç›®æ•°æ®éªŒè¯æŠ¥å‘Š")
    report_lines.append("=" * 80)
    report_lines.append(f"\næ€»é¢˜ç›®æ•°: {len(questions)}")
    report_lines.append(f"æ€»å›¾ç‰‡å¼•ç”¨æ•°: {sum(len(usages) for usages in image_usage.values())}")
    report_lines.append(f"å”¯ä¸€å›¾ç‰‡æ•°: {len(image_usage)}")
    
    # ç¼ºå¤±å›¾ç‰‡æŠ¥å‘Š
    report_lines.append("\n" + "=" * 80)
    report_lines.append("1. ç¼ºå¤±å›¾ç‰‡æ£€æŸ¥")
    report_lines.append("=" * 80)
    if missing_images:
        report_lines.append(f"\nâŒ å‘ç° {len(missing_images)} ä¸ªç¼ºå¤±çš„å›¾ç‰‡æ–‡ä»¶:")
        for missing in missing_images[:20]:
            report_lines.append(f"  é¢˜ç›®ID: {missing['question_id']}")
            report_lines.append(f"  å›¾ç‰‡è·¯å¾„: {missing['image_path']}")
            if 'option' in missing:
                report_lines.append(f"  é€‰é¡¹: {missing['option']}")
            report_lines.append("")
        if len(missing_images) > 20:
            report_lines.append(f"  ... è¿˜æœ‰ {len(missing_images) - 20} ä¸ªç¼ºå¤±å›¾ç‰‡")
    else:
        report_lines.append("\nâœ… æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶éƒ½å­˜åœ¨")
    
    # å›¾ç‰‡é‡å¤ä½¿ç”¨æŠ¥å‘Š
    report_lines.append("\n" + "=" * 80)
    report_lines.append("2. å›¾ç‰‡é‡å¤ä½¿ç”¨æ£€æŸ¥")
    report_lines.append("=" * 80)
    if duplicate_image_issues:
        report_lines.append(f"\nâš ï¸  å‘ç° {len(duplicate_image_issues)} ä¸ªå›¾ç‰‡è¢«å¤šä¸ªä¸åŒé¢˜ç›®ä½¿ç”¨:")
        report_lines.append("  (è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœå¤šä¸ªé¢˜ç›®ç¡®å®ä½¿ç”¨ç›¸åŒçš„å›¾ç‰‡)")
        report_lines.append("  (ä½†ä¹Ÿå¯èƒ½æ˜¯æŠ“å–æ—¶çš„bugï¼Œå¯¼è‡´å¤šä¸ªé¢˜ç›®ä½¿ç”¨äº†é”™è¯¯çš„å›¾ç‰‡)\n")
        
        for issue in duplicate_image_issues[:20]:
            report_lines.append(f"å›¾ç‰‡: {issue['image_path']}")
            report_lines.append(f"  è¢« {issue['usage_count']} ä¸ªå¼•ç”¨ä½¿ç”¨ï¼Œæ¶‰åŠ {issue['unique_questions']} ä¸ªä¸åŒé¢˜ç›®")
            report_lines.append("  ä½¿ç”¨ç¤ºä¾‹:")
            for usage in issue['usages']:
                report_lines.append(f"    - {usage['id']}: {usage['question']}")
            report_lines.append("")
        
        if len(duplicate_image_issues) > 20:
            report_lines.append(f"  ... è¿˜æœ‰ {len(duplicate_image_issues) - 20} ä¸ªé‡å¤å›¾ç‰‡é—®é¢˜")
        
        # ç‰¹åˆ«å…³æ³¨é‚£äº›è¢«å¤§é‡é¢˜ç›®ä½¿ç”¨çš„å›¾ç‰‡
        high_usage = [issue for issue in duplicate_image_issues if issue['usage_count'] > 10]
        if high_usage:
            report_lines.append(f"\nâš ï¸  ç‰¹åˆ«å…³æ³¨: {len(high_usage)} ä¸ªå›¾ç‰‡è¢«è¶…è¿‡10ä¸ªé¢˜ç›®ä½¿ç”¨:")
            for issue in high_usage[:10]:
                report_lines.append(f"  - {issue['image_path']}: {issue['usage_count']} ä¸ªé¢˜ç›®")
    else:
        report_lines.append("\nâœ… æ²¡æœ‰å‘ç°å¼‚å¸¸çš„å›¾ç‰‡é‡å¤ä½¿ç”¨")
    
    # é¢˜ç›®å®Œæ•´æ€§æ£€æŸ¥
    report_lines.append("\n" + "=" * 80)
    report_lines.append("3. é¢˜ç›®å®Œæ•´æ€§æ£€æŸ¥")
    report_lines.append("=" * 80)
    
    incomplete_questions = []
    for question in questions:
        issues = []
        question_id = question.get("id", "")
        
        if not question.get("question"):
            issues.append("ç¼ºå°‘é¢˜ç›®æ–‡æœ¬")
        if not question.get("options") or len(question["options"]) < 2:
            issues.append(f"é€‰é¡¹æ•°é‡ä¸è¶³: {len(question.get('options', []))}")
        if not question.get("correctAnswer"):
            issues.append("ç¼ºå°‘æ­£ç¡®ç­”æ¡ˆ")
        
        # æ£€æŸ¥æ­£ç¡®ç­”æ¡ˆæ˜¯å¦åœ¨é€‰é¡¹ä¸­
        correct_answer = question.get("correctAnswer", "").strip().upper()
        option_labels = {opt.get("label", "").strip().upper() for opt in question.get("options", [])}
        if correct_answer and correct_answer not in option_labels:
            issues.append(f"æ­£ç¡®ç­”æ¡ˆ '{correct_answer}' ä¸åœ¨é€‰é¡¹ä¸­")
        
        if issues:
            incomplete_questions.append({
                "id": question_id,
                "issues": issues
            })
    
    if incomplete_questions:
        report_lines.append(f"\nâŒ å‘ç° {len(incomplete_questions)} ä¸ªé¢˜ç›®å­˜åœ¨é—®é¢˜:")
        for q in incomplete_questions[:20]:
            report_lines.append(f"  é¢˜ç›®ID: {q['id']}")
            for issue in q['issues']:
                report_lines.append(f"    - {issue}")
            report_lines.append("")
        if len(incomplete_questions) > 20:
            report_lines.append(f"  ... è¿˜æœ‰ {len(incomplete_questions) - 20} ä¸ªé¢˜ç›®å­˜åœ¨é—®é¢˜")
    else:
        report_lines.append("\nâœ… æ‰€æœ‰é¢˜ç›®æ•°æ®å®Œæ•´")
    
    # ç»Ÿè®¡æ‘˜è¦
    report_lines.append("\n" + "=" * 80)
    report_lines.append("ç»Ÿè®¡æ‘˜è¦")
    report_lines.append("=" * 80)
    report_lines.append(f"æ€»é¢˜ç›®æ•°: {len(questions)}")
    report_lines.append(f"ç¼ºå¤±å›¾ç‰‡: {len(missing_images)}")
    report_lines.append(f"å›¾ç‰‡é‡å¤ä½¿ç”¨é—®é¢˜: {len(duplicate_image_issues)}")
    report_lines.append(f"ä¸å®Œæ•´é¢˜ç›®: {len(incomplete_questions)}")
    report_lines.append("=" * 80)
    
    # ä¿å­˜æŠ¥å‘Š
    report_content = "\n".join(report_lines)
    with open(REPORT_FILE, "w", encoding="utf-8") as f:
        f.write(report_content)
    
    print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {REPORT_FILE}")
    print("\næŠ¥å‘Šæ‘˜è¦:")
    print(f"  æ€»é¢˜ç›®æ•°: {len(questions)}")
    print(f"  ç¼ºå¤±å›¾ç‰‡: {len(missing_images)}")
    print(f"  å›¾ç‰‡é‡å¤ä½¿ç”¨é—®é¢˜: {len(duplicate_image_issues)}")
    print(f"  ä¸å®Œæ•´é¢˜ç›®: {len(incomplete_questions)}")
    
    # è¾“å‡ºå…³é”®é—®é¢˜
    if duplicate_image_issues:
        print("\nâš ï¸  å…³é”®é—®é¢˜: å‘ç°å›¾ç‰‡é‡å¤ä½¿ç”¨ï¼Œå¯èƒ½è¡¨ç¤ºæŠ“å–æ—¶å›¾ç‰‡å‘½åæœ‰bug")
        high_usage = [issue for issue in duplicate_image_issues if issue['usage_count'] > 10]
        if high_usage:
            print(f"  å…¶ä¸­ {len(high_usage)} ä¸ªå›¾ç‰‡è¢«è¶…è¿‡10ä¸ªé¢˜ç›®ä½¿ç”¨ï¼Œè¿™å¾ˆå¯èƒ½æ˜¯ä¸æ­£å¸¸çš„")

if __name__ == "__main__":
    generate_report()
